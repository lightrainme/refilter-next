import { NextRequest, NextResponse } from "next/server";
import OpenAI from "openai";
import fs from "fs";
import path from "path";

// âœ… ìºì‹œ ë§Œë£Œì¼ ì„¤ì • (ë‹¨ìœ„: ì¼)
// ì—°ìš°ê°€ ì´ ìˆ«ìë§Œ ë°”ê¾¸ë©´ ìë™ ê°±ì‹  ì£¼ê¸°ë¥¼ ì‰½ê²Œ ë³€ê²½í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
const CACHE_TTL_DAYS = 7;

// âœ… OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
// process.env.OPENAI_API_KEY í™˜ê²½ë³€ìˆ˜ì—ì„œ API í‚¤ë¥¼ ì½ì–´ì˜µë‹ˆë‹¤.
const client = new OpenAI({ apiKey: process.env.OPENAI_API_KEY });

// âœ… ìºì‹œ íŒŒì¼ ê²½ë¡œ ì„¤ì •
// í”„ë¡œì íŠ¸ ë£¨íŠ¸(process.cwd()) ê¸°ì¤€ìœ¼ë¡œ cache/reviews.json íŒŒì¼ì„ ì €ì¥í•©ë‹ˆë‹¤.
const cachePath = path.join(process.cwd(), "cache", "reviews.json");

// âœ… ìºì‹œ ë¡œë“œ í•¨ìˆ˜
// ìºì‹œ íŒŒì¼ì´ ì¡´ì¬í•˜ë©´ JSONìœ¼ë¡œ ì½ì–´ì˜¤ê³ , ì—†ìœ¼ë©´ ë¹ˆ ê°ì²´ ë°˜í™˜
function loadCache() {
  if (!fs.existsSync(cachePath)) return {};
  try {
    return JSON.parse(fs.readFileSync(cachePath, "utf8") || "{}");
  } catch {
    return {};
  }
}

// âœ… ìºì‹œ ì €ì¥ í•¨ìˆ˜
// ë””ë ‰í† ë¦¬ê°€ ì—†ì„ ê²½ìš° ìƒì„±í•˜ê³  JSON íŒŒì¼ë¡œ ì €ì¥
function saveCache(cache: Record<string, any>) {
  fs.mkdirSync(path.dirname(cachePath), { recursive: true });
  fs.writeFileSync(cachePath, JSON.stringify(cache, null, 2), "utf8");
}

// âœ… ìºì‹œ ë§Œë£Œ ì—¬ë¶€ë¥¼ ê³„ì‚°í•˜ëŠ” í•¨ìˆ˜
function isExpired(item: any) {
  if (!item?.updatedAt) return true;
  const now = new Date();
  const updatedAt = new Date(item.updatedAt);
  const diffDays = (now.getTime() - updatedAt.getTime()) / (1000 * 60 * 60 * 24);
  return diffDays > CACHE_TTL_DAYS;
}

// âœ… POST ìš”ì²­ í•¸ë“¤ëŸ¬
// ìƒí’ˆ ì´ë¦„(í•˜ë‚˜ ë˜ëŠ” ì—¬ëŸ¬ ê°œ)ì„ ë°›ì•„ ê° ìƒí’ˆì˜ ë¦¬ë·° ìš”ì•½(ì¥ì /ë‹¨ì )ì„ ìƒì„±í•©ë‹ˆë‹¤.
export async function POST(req: NextRequest) {
  // í´ë¼ì´ì–¸íŠ¸ì—ì„œ ë³´ë‚¸ JSON ìš”ì²­ ë°”ë”” íŒŒì‹±
  const body = await req.json();
  const { productName, productNames, refresh } = body;

  // productNamesê°€ ë°°ì—´ì´ë©´ ê·¸ëŒ€ë¡œ ì‚¬ìš©, ë‹¨ì¼ productNameì´ë©´ ë°°ì—´ë¡œ ë³€í™˜
  const names =
    Array.isArray(productNames) && productNames.length > 0
      ? productNames
      : productName
      ? [productName]
      : [];

  // âœ… í•„ìˆ˜ê°’ ê²€ì¦
  if (names.length === 0) {
    return NextResponse.json({ error: "Missing product name(s)" }, { status: 400 });
  }

  // ê¸°ì¡´ ìºì‹œ ë¡œë“œ
  const cache = loadCache();

  // âœ… ê°±ì‹ ì´ í•„ìš”í•œ ìƒí’ˆ í•„í„°ë§
  // - ìºì‹œê°€ ì—†ê±°ë‚˜
  // - TTL(7ì¼)ì„ ì´ˆê³¼í–ˆê±°ë‚˜
  // - refresh=trueë¡œ ê°•ì œ ê°±ì‹  ìš”ì²­ëœ ê²½ìš°
  const uncached = names.filter(
    (n) => !cache[n] || isExpired(cache[n]) || refresh === true
  );

  try {
    // ìºì‹œë˜ì§€ ì•Šì•˜ê±°ë‚˜ ë§Œë£Œëœ ìƒí’ˆë§Œ GPT ìš”ì²­ ì‹¤í–‰
    for (const name of uncached) {
      // GPT í”„ë¡¬í”„íŠ¸: ì£¼ì–´ì§„ ìƒí’ˆ ì´ë¦„ì„ ê¸°ë°˜ìœ¼ë¡œ ë¦¬ë·°ì˜ ì¥ë‹¨ì  ì˜ˆì¸¡
      const prompt = `
ì•„ë˜ì˜ ìƒí’ˆ ëª©ë¡ì„ ë³´ê³ , ê° ìƒí’ˆì˜ ì†Œë¹„ì ë¦¬ë·°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì¥ì  3ê°€ì§€ì™€ ë‹¨ì  3ê°€ì§€ë¥¼ ì˜ˆì¸¡í•´ì„œ ìš”ì•½í•´ì¤˜.
JSON ë°°ì—´ë¡œ ì•„ë˜ í˜•ì‹ìœ¼ë¡œë§Œ ì¶œë ¥í•´ì¤˜.

[
  {
    "name": "ìƒí’ˆëª…",
    "pros": ["ì¥ì 1", "ì¥ì 2", "ì¥ì 3"],
    "cons": ["ë‹¨ì 1", "ë‹¨ì 2", "ë‹¨ì 3"]
  }
]

ìƒí’ˆ ëª©ë¡:
1. ${name}
      `.trim();

      // âœ… OpenAI GPT í˜¸ì¶œ (gpt-4o-mini ëª¨ë¸ ì‚¬ìš©)
      const completion = await client.chat.completions.create({
        model: "gpt-4o-mini",
        messages: [{ role: "user", content: prompt }],
        temperature: 0.7,
      });

      // GPT ì‘ë‹µ í…ìŠ¤íŠ¸ ì •ë¦¬ ë° JSON íŒŒì‹±
      let content = completion.choices[0].message?.content || "";
      content = content.replace(/```json|```/gi, "").trim();

      try {
        const parsed = JSON.parse(content);
        parsed.forEach((entry: any) => {
          if (entry?.name && entry?.pros && entry?.cons) {
            cache[entry.name] = {
              ...entry,
              updatedAt: new Date().toISOString(), // âœ… ìºì‹œ ìƒì„±ì¼ ê¸°ë¡
            };
          }
        });
      } catch (e) {
        console.error(`âš ï¸ GPT JSON íŒŒì‹± ì‹¤íŒ¨ (ìƒí’ˆ: ${name})`, e);
      }

      // âœ… GPTê°€ ì˜¬ë°”ë¥¸ JSONì„ ë°˜í™˜í•˜ì§€ ì•Šê±°ë‚˜ ë¹ˆ ë°°ì—´ì¼ ê²½ìš° ì¬ì‹œë„
      if (!cache[name] || !cache[name].pros?.length || !cache[name].cons?.length) {
        console.log(`ğŸ” ${name} ì¬ìš”ì•½ ì‹œë„ ì¤‘...`);
        try {
          const retry = await client.chat.completions.create({
            model: "gpt-4o-mini",
            messages: [{ role: "user", content: prompt }],
            temperature: 0.7,
          });

          let retryContent = retry.choices[0].message?.content || "";
          retryContent = retryContent.replace(/```json|```/gi, "").trim();

          const retryParsed = JSON.parse(retryContent);
          if (Array.isArray(retryParsed) && retryParsed[0]?.pros?.length) {
            cache[name] = {
              ...retryParsed[0],
              updatedAt: new Date().toISOString(),
            };
            console.log(`âœ… ${name} ì¬ìš”ì•½ ì„±ê³µ`);
          } else {
            console.log(`âŒ ${name} ì¬ìš”ì•½ ì‹¤íŒ¨ (ë¹ˆ ê²°ê³¼)`);
          }
        } catch (retryError) {
          console.error(`âŒ ${name} ì¬ìš”ì•½ ì¤‘ ì˜¤ë¥˜ ë°œìƒ`, retryError);
        }
      }

      // ìºì‹œê°€ ì—¬ì „íˆ ë¹„ì–´ìˆë‹¤ë©´ ê¸°ë³¸ê°’ ì €ì¥
      if (!cache[name]) {
        cache[name] = { name, pros: [], cons: [], updatedAt: new Date().toISOString() };
      }

      // âœ… ìƒí’ˆ ë‹¨ìœ„ë¡œ ìºì‹œ ë³‘í•© ë° ì €ì¥
      const currentCache = loadCache();
      currentCache[name] = cache[name];
      saveCache(currentCache);
    }

    // ìš”ì²­ëœ ìƒí’ˆë“¤ì— ëŒ€í•œ ìºì‹œ ê²°ê³¼ ë°˜í™˜
    const results = names.map((n) => cache[n] || { pros: [], cons: [] });
    return NextResponse.json(results, { status: 200 });
  } catch (error: any) {
    console.error("âŒ GPT ìš”ì•½ ì‹¤íŒ¨:", error.message);
    return NextResponse.json({ error: "Failed to generate summaries" }, { status: 500 });
  }
}